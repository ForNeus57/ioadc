{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Inteligencja Obliczeniowa w Analizie Danych Cyfrowych\n",
    "\n",
    "##\tProjekt I\n",
    "\n",
    "### Autorzy\n",
    "- Dominik Breksa\n",
    "- Robert Barcik\n",
    "- Konrad Bodzioch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2eb6a3daf248090e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-29T19:21:07.023286300Z",
     "start_time": "2024-02-29T19:21:06.600071700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from random import random\n",
    "\n",
    "from easyAI import TwoPlayerGame\n",
    "\n",
    "\n",
    "class Nimby(TwoPlayerGame):\n",
    "    \"\"\"\n",
    "    The game starts with 4 piles of 5 pieces. In turn the players\n",
    "    remove as many pieces as they want, but from one pile only. The\n",
    "    player that removes the last piece loses.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    players\n",
    "      List of the two players e.g. [HumanPlayer(), HumanPlayer()]\n",
    "\n",
    "    piles:\n",
    "      The piles the game starts with. With piles=[2,3,4,4] the\n",
    "      game will start with 1 pile of 2 pieces, 1 pile of 3 pieces, and 2\n",
    "      piles of 4 pieces.\n",
    "\n",
    "    max_removals_per_turn\n",
    "      Max number of pieces you can remove in a turn. Default is no limit.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, players=None, max_removals_per_turn=None, piles=(5, 5, 5, 5)):\n",
    "        \"\"\" Default for `piles` is 5 piles of 5 pieces. \"\"\"\n",
    "        self.players = players\n",
    "        self.piles = list(piles)\n",
    "        self.max_removals_per_turn = max_removals_per_turn\n",
    "        self.current_player = 1  # player 1 starts.\n",
    "        \n",
    "        self.random_succeeded: bool = False\n",
    "\n",
    "    def possible_moves(self):\n",
    "        return [\n",
    "            \"%d,%d\" % (i + 1, j)\n",
    "            for i in range(len(self.piles))\n",
    "            for j in range(\n",
    "                1,\n",
    "                self.piles[i] + 1\n",
    "                if self.max_removals_per_turn is None\n",
    "                else min(self.piles[i] + 1, self.max_removals_per_turn),\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    def make_move(self, move):\n",
    "        move = list(map(int, move.split(\",\")))\n",
    "        if 0.1 > random():\n",
    "            remove: int = move[1]\n",
    "        else:\n",
    "            self.random_succeeded = True\n",
    "            remove: int = move[1] - 1\n",
    "\n",
    "        self.piles[move[0] - 1] -= remove\n",
    "\n",
    "    def unmake_move(self, move):  # optional, speeds up the AI\n",
    "        move = list(map(int, move.split(\",\")))\n",
    "        if self.random_succeeded:\n",
    "            self.random_succeeded = False\n",
    "            come_back: int = move[1] - 1\n",
    "        else:\n",
    "            come_back: int = move[1]\n",
    "\n",
    "        self.piles[move[0] - 1] += come_back\n",
    "\n",
    "    def show(self):\n",
    "        print(\" \".join(map(str, self.piles)))\n",
    "\n",
    "    def win(self):\n",
    "        return max(self.piles) == 0\n",
    "\n",
    "    def is_over(self):\n",
    "        return self.win()\n",
    "\n",
    "    def scoring(self):\n",
    "        return 100 if self.win() else 0\n",
    "\n",
    "    def ttentry(self):\n",
    "        return tuple(self.piles)  # optional, speeds up AI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T19:21:07.034294900Z",
     "start_time": "2024-02-29T19:21:07.013149500Z"
    }
   },
   "id": "3a590933f7cac641",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 6\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01measyAI\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mAI\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TranspositionTable\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# we first solve the game\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Min 5, bc it doesn't start the game\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m w, d, m, tt \u001B[38;5;241m=\u001B[39m solve_with_iterative_deepening(Nimby(), \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m16\u001B[39m), win_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m80\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      7\u001B[0m w, d, \u001B[38;5;28mlen\u001B[39m(tt\u001B[38;5;241m.\u001B[39md)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ioadc\\Lib\\site-packages\\easyAI\\AI\\solving.py:73\u001B[0m, in \u001B[0;36msolve_with_iterative_deepening\u001B[1;34m(game, ai_depths, win_score, scoring, tt, verbose, **game_params)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m depth \u001B[38;5;129;01min\u001B[39;00m ai_depths:\n\u001B[0;32m     72\u001B[0m     ai \u001B[38;5;241m=\u001B[39m Negamax(depth, scoring, tt\u001B[38;5;241m=\u001B[39mtt)\n\u001B[1;32m---> 73\u001B[0m     ai(game)\n\u001B[0;32m     74\u001B[0m     alpha \u001B[38;5;241m=\u001B[39m ai\u001B[38;5;241m.\u001B[39malpha\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m verbose:\n",
      "File \u001B[1;32m~\\.conda\\envs\\ioadc\\Lib\\site-packages\\easyAI\\AI\\Negamax.py:178\u001B[0m, in \u001B[0;36mNegamax.__call__\u001B[1;34m(self, game)\u001B[0m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;124;03mReturns the AI's best move given the current state of the game.\u001B[39;00m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    174\u001B[0m scoring \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring \u001B[38;5;28;01melse\u001B[39;00m (\u001B[38;5;28;01mlambda\u001B[39;00m g: g\u001B[38;5;241m.\u001B[39mscoring())\n\u001B[0;32m    176\u001B[0m )  \u001B[38;5;66;03m# horrible hack\u001B[39;00m\n\u001B[1;32m--> 178\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha \u001B[38;5;241m=\u001B[39m negamax(\n\u001B[0;32m    179\u001B[0m     game,\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdepth,\n\u001B[0;32m    181\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdepth,\n\u001B[0;32m    182\u001B[0m     scoring,\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;241m-\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwin_score,\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;241m+\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwin_score,\n\u001B[0;32m    185\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtt,\n\u001B[0;32m    186\u001B[0m )\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m game\u001B[38;5;241m.\u001B[39mai_move\n",
      "File \u001B[1;32m~\\.conda\\envs\\ioadc\\Lib\\site-packages\\easyAI\\AI\\Negamax.py:79\u001B[0m, in \u001B[0;36mnegamax\u001B[1;34m(game, depth, origDepth, scoring, alpha, beta, tt)\u001B[0m\n\u001B[0;32m     76\u001B[0m game\u001B[38;5;241m.\u001B[39mmake_move(move)\n\u001B[0;32m     77\u001B[0m game\u001B[38;5;241m.\u001B[39mswitch_player()\n\u001B[1;32m---> 79\u001B[0m move_alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mnegamax(game, depth \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, origDepth, scoring, \u001B[38;5;241m-\u001B[39mbeta, \u001B[38;5;241m-\u001B[39malpha, tt)\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m unmake_move:\n\u001B[0;32m     82\u001B[0m     game\u001B[38;5;241m.\u001B[39mswitch_player()\n",
      "File \u001B[1;32m~\\.conda\\envs\\ioadc\\Lib\\site-packages\\easyAI\\AI\\Negamax.py:79\u001B[0m, in \u001B[0;36mnegamax\u001B[1;34m(game, depth, origDepth, scoring, alpha, beta, tt)\u001B[0m\n\u001B[0;32m     76\u001B[0m game\u001B[38;5;241m.\u001B[39mmake_move(move)\n\u001B[0;32m     77\u001B[0m game\u001B[38;5;241m.\u001B[39mswitch_player()\n\u001B[1;32m---> 79\u001B[0m move_alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mnegamax(game, depth \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, origDepth, scoring, \u001B[38;5;241m-\u001B[39mbeta, \u001B[38;5;241m-\u001B[39malpha, tt)\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m unmake_move:\n\u001B[0;32m     82\u001B[0m     game\u001B[38;5;241m.\u001B[39mswitch_player()\n",
      "    \u001B[1;31m[... skipping similar frames: negamax at line 79 (1 times)]\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ioadc\\Lib\\site-packages\\easyAI\\AI\\Negamax.py:79\u001B[0m, in \u001B[0;36mnegamax\u001B[1;34m(game, depth, origDepth, scoring, alpha, beta, tt)\u001B[0m\n\u001B[0;32m     76\u001B[0m game\u001B[38;5;241m.\u001B[39mmake_move(move)\n\u001B[0;32m     77\u001B[0m game\u001B[38;5;241m.\u001B[39mswitch_player()\n\u001B[1;32m---> 79\u001B[0m move_alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mnegamax(game, depth \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, origDepth, scoring, \u001B[38;5;241m-\u001B[39mbeta, \u001B[38;5;241m-\u001B[39malpha, tt)\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m unmake_move:\n\u001B[0;32m     82\u001B[0m     game\u001B[38;5;241m.\u001B[39mswitch_player()\n",
      "File \u001B[1;32m~\\.conda\\envs\\ioadc\\Lib\\site-packages\\easyAI\\AI\\Negamax.py:61\u001B[0m, in \u001B[0;36mnegamax\u001B[1;34m(game, depth, origDepth, scoring, alpha, beta, tt)\u001B[0m\n\u001B[0;32m     57\u001B[0m     possible_moves \u001B[38;5;241m=\u001B[39m [lookup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmove\u001B[39m\u001B[38;5;124m\"\u001B[39m]] \u001B[38;5;241m+\u001B[39m possible_moves\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 61\u001B[0m     possible_moves \u001B[38;5;241m=\u001B[39m game\u001B[38;5;241m.\u001B[39mpossible_moves()\n\u001B[0;32m     63\u001B[0m state \u001B[38;5;241m=\u001B[39m game\n\u001B[0;32m     64\u001B[0m best_move \u001B[38;5;241m=\u001B[39m possible_moves[\u001B[38;5;241m0\u001B[39m]\n",
      "Cell \u001B[1;32mIn[2], line 40\u001B[0m, in \u001B[0;36mNimby.possible_moves\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpossible_moves\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m---> 40\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, j)\n\u001B[0;32m     41\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpiles))\n\u001B[0;32m     42\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\n\u001B[0;32m     43\u001B[0m             \u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m     44\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpiles[i] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     45\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_removals_per_turn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     46\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mmin\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpiles[i] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_removals_per_turn),\n\u001B[0;32m     47\u001B[0m         )\n\u001B[0;32m     48\u001B[0m     ]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from easyAI import AI_Player, Human_Player, Negamax, solve_with_iterative_deepening\n",
    "from easyAI.AI import TranspositionTable\n",
    "\n",
    "# we first solve the game\n",
    "# Min 5, bc it doesn't start the game\n",
    "w, d, m, tt = solve_with_iterative_deepening(Nimby(), range(5, 16), win_score=80)\n",
    "w, d, len(tt.d)\n",
    "# the previous line prints -1, 16 which shows that if the\n",
    "# computer plays second with an AI depth of 16 (or 15) it will\n",
    "# always win in 16 (total) moves or less."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T19:25:35.314573600Z",
     "start_time": "2024-02-29T19:21:07.893011200Z"
    }
   },
   "id": "2374f9d1127bace4",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Now let's play (and lose !) against the AI\n",
    "ai = Negamax(16, tt=TranspositionTable())\n",
    "game = Nimby([Human_Player(), AI_Player(tt)])\n",
    "game.play()  # You will always lose this game !\n",
    "print(\"player %d wins\" % game.current_player)\n",
    "\n",
    "# Note that with the transposition table tt generated by\n",
    "# solve_with_iterative_deepening\n",
    "# we can setup a perfect AI which doesn't have to think:\n",
    "# >>> game = Nim( [ Human_Player(), AI_Player( tt )])\n",
    "# >>> game.play() # You will always lose this game too!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec36a4ac34fc3a5a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "90cf05703e8233a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ioadc",
   "language": "python",
   "display_name": "IOADC"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
